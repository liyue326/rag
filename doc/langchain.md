ä»€ä¹ˆæ˜¯LangChain
LangChainèµ·æº
LangChainå…­å¤§ä¸»è¦é¢†åŸŸ
LangChainçš„ä¸»è¦ä»·å€¼ç»„ä»¶
LangChainç»„ä»¶
æ•°æ®è¿æ¥ç»„ä»¶data connection
data connectionæ•´ä½“æµç¨‹
data connectionâ€”â€”æ–‡æ¡£åŠ è½½å™¨
data connectionâ€”â€”æ–‡æ¡£è½¬æ¢
æ¨¡å‹IOç»„ä»¶
Chainé“¾ç»„ä»¶
é“¾çš„åºåˆ—åŒ–ï¼Œä¿å­˜é“¾åˆ°ç£ç›˜ï¼Œä»ç£ç›˜åŠ è½½é“¾ï¼š
æ€»ç»“
å‚è€ƒæ–‡çŒ®
ä»€ä¹ˆæ˜¯LangChain
LangChain: ä¸€ä¸ªè®©ä½ çš„LLMå˜å¾—æ›´å¼ºå¤§çš„å¼€æºæ¡†æ¶ã€‚LangChain å°±æ˜¯ä¸€ä¸ª LLM ç¼–ç¨‹æ¡†æ¶ï¼Œä½ æƒ³å¼€å‘ä¸€ä¸ªåŸºäº LLM åº”ç”¨ï¼Œéœ€è¦ä»€ä¹ˆç»„ä»¶å®ƒéƒ½æœ‰ï¼Œç›´æ¥ä½¿ç”¨å°±è¡Œï¼›ç”šè‡³é’ˆå¯¹å¸¸è§„çš„åº”ç”¨æµç¨‹ï¼Œå®ƒåˆ©ç”¨é“¾(LangChainä¸­Chainçš„ç”±æ¥)è¿™ä¸ªæ¦‚å¿µå·²ç»å†…ç½®æ ‡å‡†åŒ–æ–¹æ¡ˆäº†ã€‚ä¸‹é¢æˆ‘ä»¬ä»æ–°å…´çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯æ ˆçš„è§’åº¦æ¥çœ‹çœ‹ä¸ºä½•å®ƒçš„ç†å¿µè¿™ä¹ˆå—æ¬¢è¿ã€‚

LangChainèµ·æº
LangChain çš„ä½œè€…æ˜¯ Harrison Chaseï¼Œæœ€åˆæ˜¯äº 2022 å¹´ 10 æœˆå¼€æºçš„ä¸€ä¸ªé¡¹ç›®ï¼Œåœ¨ GitHub ä¸Šè·å¾—å¤§é‡å…³æ³¨ä¹‹åè¿…é€Ÿè½¬å˜ä¸ºä¸€å®¶åˆåˆ›å…¬å¸ã€‚2017 å¹´ Harrison Chase è¿˜åœ¨å“ˆä½›ä¸Šå¤§å­¦ï¼Œå¦‚ä»Šå·²æ˜¯ç¡…è°·çš„ä¸€å®¶çƒ­é—¨åˆåˆ›å…¬å¸çš„ CEOï¼Œè¿™å¯¹ä»–æ¥è¯´æ˜¯ä¸€æ¬¡é‡å¤§è€Œè¿…é€Ÿçš„è·ƒè¿ã€‚Insider ç‹¬å®¶æŠ¥é“ï¼Œäººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸ LangChain åœ¨ç§å­è½®ä¸€å‘¨åï¼Œå†æ¬¡è·å¾—çº¢æ‰é¢†æŠ•çš„ 2000 ä¸‡è‡³ 2500 ä¸‡ç¾å…ƒèèµ„ï¼Œä¼°å€¼è¾¾åˆ° 2 äº¿ç¾å…ƒã€‚

LangChainå…­å¤§ä¸»è¦é¢†åŸŸ
ç®¡ç†å’Œä¼˜åŒ–promptã€‚ä¸åŒçš„ä»»åŠ¡ä½¿ç”¨ä¸åŒpromptï¼Œå¦‚ä½•å»ç®¡ç†å’Œä¼˜åŒ–è¿™äº›promptæ˜¯langchainçš„ä¸»è¦åŠŸèƒ½ä¹‹ä¸€ã€‚
é“¾ï¼Œåˆæ­¥ç†è§£ä¸ºä¸€ä¸ªå…·ä½“ä»»åŠ¡ä¸­ä¸åŒå­ä»»åŠ¡ä¹‹é—´çš„ä¸€ä¸ªè°ƒç”¨ã€‚
æ•°æ®å¢å¼ºçš„ç”Ÿæˆï¼Œæ•°æ®å¢å¼ºç”Ÿæˆæ¶‰åŠç‰¹å®šç±»å‹çš„é“¾ï¼Œå®ƒé¦–å…ˆä¸å¤–éƒ¨æ•°æ®æºäº¤äº’ä»¥è·å–æ•°æ®ç”¨äºç”Ÿæˆæ­¥éª¤ã€‚è¿™æ–¹é¢çš„ä¾‹å­åŒ…æ‹¬å¯¹é•¿ç¯‡æ–‡å­—çš„æ€»ç»“å’Œå¯¹ç‰¹å®šæ•°æ®æºçš„æé—®/å›ç­”ã€‚
ä»£ç†ï¼Œæ ¹æ®ä¸åŒçš„æŒ‡ä»¤é‡‡å–ä¸åŒçš„è¡ŒåŠ¨ï¼Œç›´åˆ°æ•´ä¸ªæµç¨‹å®Œæˆä¸ºæ­¢ã€‚
è¯„ä¼°ï¼Œç”Ÿæˆå¼æ¨¡å‹æ˜¯å‡ºäº†åçš„éš¾ä»¥ç”¨ä¼ ç»Ÿçš„æŒ‡æ ‡æ¥è¯„ä¼°ã€‚è¯„ä¼°å®ƒä»¬çš„ä¸€ä¸ªæ–°æ–¹æ³•æ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹æœ¬èº«æ¥è¿›è¡Œè¯„ä¼°ã€‚LangChainæä¾›äº†ä¸€äº›æç¤º/é“¾æ¥ååŠ©è¿™ä¸ªå·¥ä½œã€‚
å†…å­˜ï¼šåœ¨æ•´ä¸ªæµç¨‹ä¸­å¸®æˆ‘ä»¬ç®¡ç†ä¸€äº›ä¸­é—´çŠ¶æ€ã€‚
æ€»çš„æ¥è¯´LangChainå¯ä»¥ç†è§£ä¸ºï¼šåœ¨ä¸€ä¸ªæµç¨‹çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸä¸­ï¼Œç®¡ç†å’Œä¼˜åŒ–promptï¼Œæ ¹æ®promptä½¿ç”¨ä¸åŒçš„ä»£ç†è¿›è¡Œä¸åŒçš„åŠ¨ä½œï¼Œåœ¨è¿™æœŸé—´ä½¿ç”¨å†…å­˜ç®¡ç†ä¸­é—´çš„ä¸€äº›çŠ¶æ€ï¼Œç„¶åä½¿ç”¨é“¾å°†ä¸åŒä»£ç†ä¹‹é—´è¿›è¡Œè¿æ¥èµ·æ¥ï¼Œæœ€ç»ˆå½¢æˆä¸€ä¸ªé—­ç¯ã€‚

LangChainçš„ä¸»è¦ä»·å€¼ç»„ä»¶
ç»„ä»¶ï¼šç”¨äºå¤„ç†è¯­è¨€æ¨¡å‹çš„æŠ½è±¡æ¦‚å¿µï¼Œä»¥åŠæ¯ä¸ªæŠ½è±¡æ¦‚å¿µçš„å®ç°é›†åˆã€‚æ— è®ºä½ æ˜¯å¦ä½¿ç”¨LangChainæ¡†æ¶çš„å…¶ä»–éƒ¨åˆ†ï¼Œç»„ä»¶éƒ½æ˜¯æ¨¡å—åŒ–çš„ï¼Œæ˜“äºä½¿ç”¨ã€‚
ç°æˆçš„é“¾ï¼šç”¨äºå®Œæˆç‰¹å®šé«˜çº§ä»»åŠ¡çš„ç»„ä»¶çš„ç»“æ„åŒ–ç»„åˆã€‚ç°æˆçš„é“¾ä½¿äººå®¹æ˜“ä¸Šæ‰‹ã€‚å¯¹äºæ›´å¤æ‚çš„åº”ç”¨å’Œç»†å¾®çš„ç”¨ä¾‹ï¼Œç»„ä»¶ä½¿å¾—å®šåˆ¶ç°æœ‰é“¾æˆ–å»ºç«‹æ–°é“¾å˜å¾—å®¹æ˜“ã€‚
LangChainç»„ä»¶
model I/Oï¼šè¯­è¨€æ¨¡å‹æ¥å£
data connectionï¼šä¸ç‰¹å®šä»»åŠ¡çš„æ•°æ®æ¥å£
chainsï¼šæ„å»ºè°ƒç”¨åºåˆ—
agentsï¼šç»™å®šé«˜çº§æŒ‡ä»¤ï¼Œè®©é“¾é€‰æ‹©ä½¿ç”¨å“ªäº›å·¥å…·
memoryï¼šåœ¨ä¸€ä¸ªé“¾çš„è¿è¡Œä¹‹é—´ä¿æŒåº”ç”¨çŠ¶æ€
callbacksï¼šè®°å½•å¹¶æµå¼ä¼ è¾“ä»»ä½•é“¾çš„ä¸­é—´æ­¥éª¤
indexesï¼šç´¢å¼•æŒ‡çš„æ˜¯ç»“æ„åŒ–æ–‡ä»¶çš„æ–¹æ³•ï¼Œä»¥ä¾¿LLMèƒ½å¤Ÿä¸å®ƒä»¬è¿›è¡Œæœ€å¥½çš„äº¤äº’
æ•°æ®è¿æ¥ç»„ä»¶data connection
LLMåº”ç”¨éœ€è¦ç”¨æˆ·ç‰¹å®šçš„æ•°æ®ï¼Œè¿™äº›æ•°æ®ä¸å±äºæ¨¡å‹çš„è®­ç»ƒé›†ã€‚LangChainé€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›äº†åŠ è½½ã€è½¬æ¢ã€å­˜å‚¨å’ŒæŸ¥è¯¢æ•°æ®çš„æ„å»ºæ¨¡å—ï¼š

æ–‡æ¡£åŠ è½½å™¨ï¼šä»è®¸å¤šä¸åŒçš„æ¥æºåŠ è½½æ–‡æ¡£
æ–‡æ¡£è½¬æ¢å™¨ï¼šåˆ†å‰²æ–‡æ¡£ï¼Œåˆ é™¤å¤šä½™çš„æ–‡æ¡£ç­‰
æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼šé‡‡å–éç»“æ„åŒ–æ–‡æœ¬ï¼Œå¹¶æŠŠå®ƒå˜æˆä¸€ä¸ªæµ®ç‚¹æ•°çš„åˆ—è¡¨ çŸ¢é‡å­˜å‚¨ï¼šå­˜å‚¨å’Œæœç´¢åµŒå…¥å¼æ•°æ®
æ£€ç´¢å™¨ï¼šæŸ¥è¯¢ä½ çš„æ•°æ®
data connectionæ•´ä½“æµç¨‹

data connectionâ€”â€”æ–‡æ¡£åŠ è½½å™¨
pythonå®‰è£…åŒ…å‘½ä»¤ï¼š

pip install langchain
pip install unstructured
pip install jq
CSVåŸºæœ¬ç”¨æ³•

import os
from pathlib import Path

from langchain.document_loaders import UnstructuredCSVLoader
from langchain.document_loaders.csv_loader import CSVLoader
EXAMPLE_DIRECTORY = file_path = Path(__file__).parent.parent / "examples"


def test_unstructured_csv_loader() -> None:
    """Test unstructured loader."""
    file_path = os.path.join(EXAMPLE_DIRECTORY, "stanley-cups.csv")
    loader = UnstructuredCSVLoader(str(file_path))
    docs = loader.load()
    print(docs)
    assert len(docs) == 1

def test_csv_loader():
  file_path = os.path.join(EXAMPLE_DIRECTORY, "stanley-cups.csv")
  loader = CSVLoader(file_path)
  docs = loader.load()
  print(docs)

test_unstructured_csv_loader()
test_csv_loader()
æ–‡ä»¶ç›®å½•ç”¨æ³•

from langchain.document_loaders import DirectoryLoader, TextLoader

text_loader_kwargs={'autodetect_encoding': True}
loader = DirectoryLoader('../examples/', 
              glob="**/*.txt",  # éå†txtæ–‡ä»¶
              show_progress=True,  # æ˜¾ç¤ºè¿›åº¦
              use_multithreading=True,  # ä½¿ç”¨å¤šçº¿ç¨‹
              loader_cls=TextLoader,  # ä½¿ç”¨åŠ è½½æ•°æ®çš„æ–¹å¼
              silent_errors=True,  # é‡åˆ°é”™è¯¯ç»§ç»­
              loader_kwargs=text_loader_kwargs)  # å¯ä»¥ä½¿ç”¨å­—å…¸ä¼ å…¥å‚æ•°

docs = loader.load()
print("\n")
print(docs[0])
HTMLç”¨æ³•

from langchain.document_loaders import UnstructuredHTMLLoader, BSHTMLLoader
loader = UnstructuredHTMLLoader("../examples/example.html")
docs = loader.load()
print(docs[0])

loader = BSHTMLLoader("../examples/example.html")
docs = loader.load()
print(docs[0])
JSONç”¨æ³•

import json
from pathlib import Path
from pprint import pprint


file_path='../examples/facebook_chat.json'
data = json.loads(Path(file_path).read_text())
pprint(data)

"""
{'image': {'creation_timestamp': 1675549016, 'uri': 'image_of_the_chat.jpg'},
 'is_still_participant': True,
 'joinable_mode': {'link': '', 'mode': 1},
 'magic_words': [],
 'messages': [{'content': 'Bye!',
               'sender_name': 'User 2',
               'timestamp_ms': 1675597571851},
              {'content': 'Oh no worries! Bye',
               'sender_name': 'User 1',
               'timestamp_ms': 1675597435669},
              {'content': 'No Im sorry it was my mistake, the blue one is not '
                          'for sale',
               'sender_name': 'User 2',
               'timestamp_ms': 1675596277579},
              {'content': 'I thought you were selling the blue one!',
               'sender_name': 'User 1',
               'timestamp_ms': 1675595140251},
              {'content': 'Im not interested in this bag. Im interested in the '
                          'blue one!',
               'sender_name': 'User 1',
               'timestamp_ms': 1675595109305},
              {'content': 'Here is $129',
               'sender_name': 'User 2',
               'timestamp_ms': 1675595068468},
              {'photos': [{'creation_timestamp': 1675595059,
                           'uri': 'url_of_some_picture.jpg'}],
               'sender_name': 'User 2',
               'timestamp_ms': 1675595060730},
              {'content': 'Online is at least $100',
               'sender_name': 'User 2',
               'timestamp_ms': 1675595045152},
              {'content': 'How much do you want?',
               'sender_name': 'User 1',
               'timestamp_ms': 1675594799696},
              {'content': 'Goodmorning! $50 is too low.',
               'sender_name': 'User 2',
               'timestamp_ms': 1675577876645},
              {'content': 'Hi! Im interested in your bag. Im offering $50. Let '
                          'me know if you are interested. Thanks!',
               'sender_name': 'User 1',
               'timestamp_ms': 1675549022673}],
 'participants': [{'name': 'User 1'}, {'name': 'User 2'}],
 'thread_path': 'inbox/User 1 and User 2 chat',
 'title': 'User 1 and User 2 chat'}
"""
ä½¿ç”¨langchainåŠ è½½æ•°æ®ï¼š
```python
from langchain.document_loaders import JSONLoader
loader = JSONLoader(
    file_path='../examples/facebook_chat.json',
    jq_schema='.messages[].content' # ä¼šæŠ¥é”™Expected page_content is string, got <class 'NoneType'> instead.
    page_content=False, # æŠ¥é”™åæ·»åŠ è¿™ä¸€è¡Œ)

data = loader.load()
print(data[0])
PDFç”¨æ³•

'''
ç¬¬ä¸€ç§ç”¨æ³•
'''
from langchain.document_loaders import PyPDFLoader

loader = PyPDFLoader("../examples/layout-parser-paper.pdf")
pages = loader.load_and_split()

print(pages[0])

'''
ç¬¬äºŒç§ç”¨æ³•
'''
from langchain.document_loaders import MathpixPDFLoader

loader = MathpixPDFLoader("example_data/layout-parser-paper.pdf")

data = loader.load()
print(data[0])

'''
ç¬¬ä¸‰ç§ç”¨æ³•
'''
from langchain.document_loaders import UnstructuredPDFLoader

loader = UnstructuredPDFLoader("../examples/layout-parser-paper.pdf")

data = loader.load()
print(data[0])
data connectionâ€”â€”æ–‡æ¡£è½¬æ¢
åŠ è½½äº†æ–‡ä»¶åï¼Œç»å¸¸ä¼šéœ€è¦è½¬æ¢å®ƒä»¬ä»¥æ›´å¥½åœ°é€‚åº”åº”ç”¨ã€‚æœ€ç®€å•çš„ä¾‹å­æ˜¯ï¼Œä½ å¯èƒ½æƒ³æŠŠä¸€ä¸ªé•¿çš„æ–‡æ¡£åˆ†å‰²æˆè¾ƒå°çš„å—çŠ¶ï¼Œä»¥é€‚åº”ä½ çš„æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£ã€‚LangChainæœ‰è®¸å¤šå†…ç½®çš„æ–‡æ¡£è½¬æ¢å·¥å…·ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å‰²ã€ç»„åˆã€è¿‡æ»¤å’Œå…¶ä»–æ“ä½œã€‚

é€šè¿‡å­—ç¬¦è¿›è¡Œæ–‡æœ¬åˆ†å‰²

state_of_the_union = """
æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€

    æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦

    â€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦

    ä¸­å¹´ç”·å­è¯åˆšåˆšè„±å£ï¼Œä¾¿æ˜¯ä¸å‡ºæ„å¤–çš„åœ¨äººå¤´æ±¹æ¶Œçš„å¹¿åœºä¸Šå¸¦èµ·äº†ä¸€é˜µå˜²è®½çš„éªšåŠ¨ã€‚

    â€œä¸‰æ®µï¼Ÿå˜¿å˜¿ï¼Œæœç„¶ä¸å‡ºæˆ‘æ‰€æ–™ï¼Œè¿™ä¸ªâ€œå¤©æ‰â€è¿™ä¸€å¹´åˆæ˜¯åœ¨åŸåœ°è¸æ­¥ï¼â€

    â€œå“ï¼Œè¿™åºŸç‰©çœŸæ˜¯æŠŠå®¶æ—çš„è„¸éƒ½ç»™ä¸¢å…‰äº†ã€‚â€

    â€œè¦ä¸æ˜¯æ—é•¿æ˜¯ä»–çš„çˆ¶äº²ï¼Œè¿™ç§åºŸç‰©ï¼Œæ—©å°±è¢«é©±èµ¶å‡ºå®¶æ—ï¼Œä»»å…¶è‡ªç”Ÿè‡ªç­äº†ï¼Œå“ªè¿˜æœ‰æœºä¼šå¾…åœ¨å®¶æ—ä¸­ç™½åƒç™½å–ã€‚â€

    â€œå”‰ï¼Œæ˜”å¹´é‚£åé—»ä¹Œå¦åŸçš„å¤©æ‰å°‘å¹´ï¼Œå¦‚ä»Šæ€ä¹ˆè½é­„æˆè¿™èˆ¬æ¨¡æ ·äº†å•Šï¼Ÿâ€
"""

from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(        
    separator = "\n\n",
    chunk_size = 128,  # åˆ†å—é•¿åº¦
    chunk_overlap  = 10,  # é‡åˆçš„æ–‡æœ¬é•¿åº¦
    length_function = len,
)

texts = text_splitter.create_documents([state_of_the_union])
print(texts[0])

# è¿™é‡Œmetadatasç”¨äºåŒºåˆ†ä¸åŒçš„æ–‡æ¡£
metadatas = [{"document": 1}, {"document": 2}]
documents = text_splitter.create_documents([state_of_the_union, state_of_the_union], metadatas=metadatas)
pprint(documents)

# è·å–åˆ‡å‰²åçš„æ–‡æœ¬
print(text_splitter.split_text(state_of_the_union)[0])
å¯¹ä»£ç è¿›è¡Œåˆ†å‰²

from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    Language,
)

print([e.value for e in Language])  # æ”¯æŒè¯­è¨€
print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON))  # åˆ†å‰²ç¬¦å·

PYTHON_CODE = """
def hello_world():
    print("Hello, World!")

# Call the function
hello_world()
"""
python_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON, chunk_size=50, chunk_overlap=0
)
python_docs = python_splitter.create_documents([PYTHON_CODE])
python_docs

"""
[Document(page_content='def hello_world():\n    print("Hello, World!")', metadata={}),
 Document(page_content='# Call the function\nhello_world()', metadata={})]
"""
é€šè¿‡markdownheaderè¿›è¡Œåˆ†å‰²

ä¸¾ä¸ªä¾‹å­ï¼šmd = # Foo\n\n ## Bar\n\nHi this is Jim \nHi this is Joe\n\n ## Baz\n\n Hi this is Molly' .æˆ‘ä»¬å®šä¹‰åˆ†å‰²å¤´ï¼š[("#", "Header 1"),("##", "Header 2")]æ–‡æœ¬åº”è¯¥è¢«å…¬å…±å¤´è¿›è¡Œåˆ†å‰²ï¼Œæœ€ç»ˆå¾—åˆ°ï¼š`{'content': 'Hi this is Jim \nHi this is Joe', 'metadata': {'Header 1': 'Foo', 'Header 2': 'Bar'}} {'content': 'Hi this is Molly', 'metadata': {'Header 1': 'Foo', 'Header 2': 'Baz'}}

from langchain.text_splitter import MarkdownHeaderTextSplitter
markdown_document = "# Foo\n\n    ## Bar\n\nHi this is Jim\n\nHi this is Joe\n\n ### Boo \n\n Hi this is Lance \n\n ## Baz\n\n Hi this is Molly"

headers_to_split_on = [
    ("#", "Header 1"),
    ("##", "Header 2"),
    ("###", "Header 3"),
]

markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
md_header_splits = markdown_splitter.split_text(markdown_document)
md_header_splits

"""
    [Document(page_content='Hi this is Jim  \nHi this is Joe', metadata={'Header 1': 'Foo', 'Header 2': 'Bar'}),
     Document(page_content='Hi this is Lance', metadata={'Header 1': 'Foo', 'Header 2': 'Bar', 'Header 3': 'Boo'}),
     Document(page_content='Hi this is Molly', metadata={'Header 1': 'Foo', 'Header 2': 'Baz'})]
"""
é€šè¿‡å­—ç¬¦é€’å½’åˆ†å‰²

é»˜è®¤åˆ—è¡¨ä¸ºï¼š["\n\n", "\n", " ", ""]

 state_of_the_union = """
æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€

æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦

â€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦

ä¸­å¹´ç”·å­è¯åˆšåˆšè„±å£ï¼Œä¾¿æ˜¯ä¸å‡ºæ„å¤–çš„åœ¨äººå¤´æ±¹æ¶Œçš„å¹¿åœºä¸Šå¸¦èµ·äº†ä¸€é˜µå˜²è®½çš„éªšåŠ¨ã€‚

â€œä¸‰æ®µï¼Ÿå˜¿å˜¿ï¼Œæœç„¶ä¸å‡ºæˆ‘æ‰€æ–™ï¼Œè¿™ä¸ªâ€œå¤©æ‰â€è¿™ä¸€å¹´åˆæ˜¯åœ¨åŸåœ°è¸æ­¥ï¼â€

â€œå“ï¼Œè¿™åºŸç‰©çœŸæ˜¯æŠŠå®¶æ—çš„è„¸éƒ½ç»™ä¸¢å…‰äº†ã€‚â€

â€œè¦ä¸æ˜¯æ—é•¿æ˜¯ä»–çš„çˆ¶äº²ï¼Œè¿™ç§åºŸç‰©ï¼Œæ—©å°±è¢«é©±èµ¶å‡ºå®¶æ—ï¼Œä»»å…¶è‡ªç”Ÿè‡ªç­äº†ï¼Œå“ªè¿˜æœ‰æœºä¼šå¾…åœ¨å®¶æ—ä¸­ç™½åƒç™½å–ã€‚â€

â€œå”‰ï¼Œæ˜”å¹´é‚£åé—»ä¹Œå¦åŸçš„å¤©æ‰å°‘å¹´ï¼Œå¦‚ä»Šæ€ä¹ˆè½é­„æˆè¿™èˆ¬æ¨¡æ ·äº†å•Šï¼Ÿâ€
"""

from langchain.text_splitter import CharacterTextSplitter
from pprint import pprint
text_splitter = CharacterTextSplitter(
    chunk_size = 128,
    chunk_overlap  = 10,
    length_function = len,
)

texts = text_splitter.create_documents([state_of_the_union])
pprint(texts[0].page_content)

"""
('æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€\n'
 '\n'
 'æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦')
 
['æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€\n'
 '\n'
 'æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦',
 'â€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦\n'
 '\n'
 'ä¸­å¹´ç”·å­è¯åˆšåˆšè„±å£ï¼Œä¾¿æ˜¯ä¸å‡ºæ„å¤–çš„åœ¨äººå¤´æ±¹æ¶Œçš„å¹¿åœºä¸Šå¸¦èµ·äº†ä¸€é˜µå˜²è®½çš„éªšåŠ¨ã€‚']
"""
é€šè¿‡tokensè¿›è¡Œåˆ†å‰²

æˆ‘ä»¬çŸ¥é“ï¼Œè¯­è¨€æ¨¡å‹æœ‰ä¸€ä¸ªä»¤ç‰Œé™åˆ¶ã€‚ä¸åº”è¯¥è¶…è¿‡ä»¤ç‰Œçš„é™åˆ¶ã€‚å› æ­¤ï¼Œå½“ä½ æŠŠä½ çš„æ–‡æœ¬åˆ†æˆå‡ å—æ—¶ï¼Œè®¡ç®—æ ‡è®°çš„æ•°é‡æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚æœ‰è®¸å¤šæ ‡è®°å™¨ã€‚å½“ä½ è®¡ç®—æ–‡æœ¬ä¸­çš„ä»¤ç‰Œæ—¶ï¼Œä½ åº”è¯¥ä½¿ç”¨ä¸è¯­è¨€æ¨¡å‹ä¸­ä½¿ç”¨çš„ç›¸åŒçš„ä»¤ç‰Œå™¨ã€‚

å®‰è£…tiktokenå®‰è£…åŒ…

pip install tiktoken
pythonä»£ç å®ç°å¦‚ä¸‹ï¼š

state_of_the_union = """
æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€

æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦

â€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦

ä¸­å¹´ç”·å­è¯åˆšåˆšè„±å£ï¼Œä¾¿æ˜¯ä¸å‡ºæ„å¤–çš„åœ¨äººå¤´æ±¹æ¶Œçš„å¹¿åœºä¸Šå¸¦èµ·äº†ä¸€é˜µå˜²è®½çš„éªšåŠ¨ã€‚

â€œä¸‰æ®µï¼Ÿå˜¿å˜¿ï¼Œæœç„¶ä¸å‡ºæˆ‘æ‰€æ–™ï¼Œè¿™ä¸ªâ€œå¤©æ‰â€è¿™ä¸€å¹´åˆæ˜¯åœ¨åŸåœ°è¸æ­¥ï¼â€

â€œå“ï¼Œè¿™åºŸç‰©çœŸæ˜¯æŠŠå®¶æ—çš„è„¸éƒ½ç»™ä¸¢å…‰äº†ã€‚â€

â€œè¦ä¸æ˜¯æ—é•¿æ˜¯ä»–çš„çˆ¶äº²ï¼Œè¿™ç§åºŸç‰©ï¼Œæ—©å°±è¢«é©±èµ¶å‡ºå®¶æ—ï¼Œä»»å…¶è‡ªç”Ÿè‡ªç­äº†ï¼Œå“ªè¿˜æœ‰æœºä¼šå¾…åœ¨å®¶æ—ä¸­ç™½åƒç™½å–ã€‚â€

â€œå”‰ï¼Œæ˜”å¹´é‚£åé—»ä¹Œå¦åŸçš„å¤©æ‰å°‘å¹´ï¼Œå¦‚ä»Šæ€ä¹ˆè½é­„æˆè¿™èˆ¬æ¨¡æ ·äº†å•Šï¼Ÿâ€
"""

from langchain.text_splitter import CharacterTextSplitter
from pprint import pprint
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=128, chunk_overlap=10
)
texts = text_splitter.split_text(state_of_the_union)

pprint(texts)
for text in texts:
  print(len(text))
"""
WARNING:langchain.text_splitter:Created a chunk of size 184, which is longer than the specified 128
['æ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼â€',
 'æœ›ç€æµ‹éªŒé­”çŸ³ç¢‘ä¸Šé¢é—ªäº®å¾—ç”šè‡³æœ‰äº›åˆºçœ¼çš„äº”ä¸ªå¤§å­—ï¼Œå°‘å¹´é¢æ— è¡¨æƒ…ï¼Œå”‡è§’æœ‰ç€ä¸€æŠ¹è‡ªå˜²ï¼Œç´§æ¡çš„æ‰‹æŒï¼Œå› ä¸ºå¤§åŠ›ï¼Œè€Œå¯¼è‡´ç•¥å¾®å°–é”çš„æŒ‡ç”²æ·±æ·±çš„åˆºè¿›äº†æŒå¿ƒä¹‹ä¸­ï¼Œå¸¦æ¥ä¸€é˜µé˜µé’»å¿ƒçš„ç–¼ç—›â€¦',
 'â€œè§ç‚ï¼Œæ–—ä¹‹åŠ›ï¼Œä¸‰æ®µï¼çº§åˆ«ï¼šä½çº§ï¼â€æµ‹éªŒé­”çŸ³ç¢‘ä¹‹æ—ï¼Œä¸€ä½ä¸­å¹´ç”·å­ï¼Œçœ‹äº†ä¸€çœ¼ç¢‘ä¸Šæ‰€æ˜¾ç¤ºå‡ºæ¥çš„ä¿¡æ¯ï¼Œè¯­æ°”æ¼ ç„¶çš„å°†ä¹‹å…¬å¸ƒäº†å‡ºæ¥â€¦',
 'ä¸­å¹´ç”·å­è¯åˆšåˆšè„±å£ï¼Œä¾¿æ˜¯ä¸å‡ºæ„å¤–çš„åœ¨äººå¤´æ±¹æ¶Œçš„å¹¿åœºä¸Šå¸¦èµ·äº†ä¸€é˜µå˜²è®½çš„éªšåŠ¨ã€‚',
 'â€œä¸‰æ®µï¼Ÿå˜¿å˜¿ï¼Œæœç„¶ä¸å‡ºæˆ‘æ‰€æ–™ï¼Œè¿™ä¸ªâ€œå¤©æ‰â€è¿™ä¸€å¹´åˆæ˜¯åœ¨åŸåœ°è¸æ­¥ï¼â€\n\nâ€œå“ï¼Œè¿™åºŸç‰©çœŸæ˜¯æŠŠå®¶æ—çš„è„¸éƒ½ç»™ä¸¢å…‰äº†ã€‚â€',
 'â€œè¦ä¸æ˜¯æ—é•¿æ˜¯ä»–çš„çˆ¶äº²ï¼Œè¿™ç§åºŸç‰©ï¼Œæ—©å°±è¢«é©±èµ¶å‡ºå®¶æ—ï¼Œä»»å…¶è‡ªç”Ÿè‡ªç­äº†ï¼Œå“ªè¿˜æœ‰æœºä¼šå¾…åœ¨å®¶æ—ä¸­ç™½åƒç™½å–ã€‚â€',
 'â€œå”‰ï¼Œæ˜”å¹´é‚£åé—»ä¹Œå¦åŸçš„å¤©æ‰å°‘å¹´ï¼Œå¦‚ä»Šæ€ä¹ˆè½é­„æˆè¿™èˆ¬æ¨¡æ ·äº†å•Šï¼Ÿâ€']

"""

'''
ç›´æ¥ä½¿ç”¨tiktoken
'''
from langchain.text_splitter import TokenTextSplitter

text_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=0)

texts = text_splitter.split_text(state_of_the_union)
print(texts[0])
æ¨¡å‹IOç»„ä»¶
æ¨¡å‹åŒ…æ‹¬LLMã€èŠå¤©æ¨¡å‹ã€æ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯æˆ‘ä»¬æ¶µç›–çš„ç¬¬ä¸€ç§æ¨¡å‹ç±»å‹ã€‚è¿™äº›æ¨¡å‹æ¥å—ä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ä½œä¸ºè¾“å‡ºã€‚èŠå¤©æ¨¡å‹æ˜¯æˆ‘ä»¬æ¶µç›–çš„ç¬¬äºŒç§ç±»å‹çš„æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹é€šå¸¸ç”±ä¸€ä¸ªè¯­è¨€æ¨¡å‹æ”¯æŒï¼Œä½†å®ƒä»¬çš„APIæ›´åŠ ç»“æ„åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™äº›æ¨¡å‹æ¥å—ä¸€ä¸ªèŠå¤©ä¿¡æ¯çš„åˆ—è¡¨ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªèŠå¤©ä¿¡æ¯ã€‚ç¬¬ä¸‰ç±»æ¨¡å‹æ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å°†æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæµ®ç‚¹æ•°åˆ—è¡¨ã€‚

LangChainæä¾›äº†è¿æ¥ä»»ä½•è¯­è¨€æ¨¡å‹çš„æ„å»ºæ¨¡å—ã€‚

æç¤ºï¼š æ¨¡æ¿åŒ–ã€åŠ¨æ€é€‰æ‹©å’Œç®¡ç†æ¨¡å‹è¾“å…¥
å¯¹æ¨¡å‹è¿›è¡Œç¼–ç¨‹çš„æ–°æ–¹æ³•æ˜¯é€šè¿‡æç¤ºè¯­ã€‚ä¸€ä¸ªæç¤ºæŒ‡çš„æ˜¯å¯¹æ¨¡å‹çš„è¾“å…¥ã€‚è¿™ç§è¾“å…¥é€šå¸¸æ˜¯ç”±å¤šä¸ªç»„ä»¶æ„æˆçš„ã€‚LangChainæä¾›äº†å‡ ä¸ªç±»å’Œå‡½æ•°ï¼Œä½¿æ„å»ºå’Œå¤„ç†æç¤ºä¿¡æ¯å˜å¾—å®¹æ˜“ã€‚å¸¸ç”¨çš„æ–¹æ³•æ˜¯ï¼šæç¤ºæ¨¡æ¿ï¼š å¯¹æ¨¡å‹è¾“å…¥è¿›è¡Œå‚æ•°åŒ–å¤„ï¼›ä¸ä¾‹å­é€‰æ‹©å™¨ï¼š åŠ¨æ€åœ°é€‰æ‹©è¦åŒ…å«åœ¨æç¤ºä¸­çš„ä¾‹å­ã€‚

ä¸€ä¸ªæç¤ºæ¨¡æ¿å¯ä»¥åŒ…å«ï¼šå¯¹è¯­è¨€æ¨¡å‹çš„æŒ‡ç¤ºï¼›ä¸€ç»„å°‘é‡çš„ä¾‹å­ï¼Œä»¥å¸®åŠ©è¯­è¨€æ¨¡å‹äº§ç”Ÿä¸€ä¸ªæ›´å¥½çš„ååº”ï¼›ä¸€ä¸ªå¯¹è¯­è¨€æ¨¡å‹çš„é—®é¢˜ã€‚ä¾‹å¦‚:

from langchain import PromptTemplate


template = """/
You are a naming consultant for new companies.
What is a good name for a company that makes {product}?
"""

prompt = PromptTemplate.from_template(template)
prompt.format(product="colorful socks")

"""
    You are a naming consultant for new companies.
    What is a good name for a company that makes colorful socks?
"""
å¦‚æœéœ€è¦åˆ›å»ºä¸€ä¸ªä¸è§’è‰²ç›¸å…³çš„æ¶ˆæ¯æ¨¡æ¿ï¼Œåˆ™éœ€è¦ä½¿ç”¨MessagePromptTemplateã€‚

template="You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
MessagePromptTemplateçš„ç±»å‹ï¼šLangChainæä¾›ä¸åŒç±»å‹çš„MessagePromptTemplateã€‚æœ€å¸¸ç”¨çš„æ˜¯AIMessagePromptTemplateã€SystemMessagePromptTemplateå’ŒHumanMessagePromptTemplateï¼Œå®ƒä»¬åˆ†åˆ«åˆ›å»ºAIæ¶ˆæ¯ã€ç³»ç»Ÿæ¶ˆæ¯å’Œäººç±»æ¶ˆæ¯ã€‚

é€šç”¨çš„æç¤ºæ¨¡æ¿ï¼šå‡è®¾æˆ‘ä»¬æƒ³è®©LLMç”Ÿæˆä¸€ä¸ªå‡½æ•°åç§°çš„è‹±æ–‡è§£é‡Šã€‚ä¸ºäº†å®ç°è¿™ä¸€ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„æç¤ºæ¨¡æ¿ï¼Œå°†å‡½æ•°åç§°ä½œä¸ºè¾“å…¥ï¼Œå¹¶å¯¹æç¤ºæ¨¡æ¿è¿›è¡Œæ ¼å¼åŒ–ï¼Œä»¥æä¾›è¯¥å‡½æ•°çš„æºä»£ç ã€‚

æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå®ƒå°†è¿”å›ç»™å®šçš„å‡½æ•°çš„æºä»£ç ã€‚

import inspect


def get_source_code(function_name):
    # Get the source code of the function
    return inspect.getsource(function_name)
æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„æç¤ºæ¨¡æ¿ï¼Œå°†å‡½æ•°åç§°ä½œä¸ºè¾“å…¥ï¼Œå¹¶æ ¼å¼åŒ–æç¤ºæ¨¡æ¿ä»¥æä¾›å‡½æ•°çš„æºä»£ç ã€‚


é“¾å…è®¸æˆ‘ä»¬å°†å¤šä¸ªç»„ä»¶ç»“åˆåœ¨ä¸€èµ·ï¼Œåˆ›å»ºä¸€ä¸ªå•ä¸€çš„ã€è¿è´¯çš„åº”ç”¨ç¨‹åºã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªé“¾ï¼Œæ¥å—ç”¨æˆ·è¾“å…¥ï¼Œç”¨PromptTemplateæ ¼å¼åŒ–ï¼Œç„¶åå°†æ ¼å¼åŒ–çš„å“åº”ä¼ é€’ç»™LLMã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†å¤šä¸ªé“¾ç»„åˆåœ¨ä¸€èµ·ï¼Œæˆ–å°†é“¾ä¸å…¶ä»–ç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ï¼Œå»ºç«‹æ›´å¤æ‚çš„é“¾ã€‚LLMChainæ˜¯æœ€åŸºæœ¬çš„æ„å»ºå—é“¾ã€‚å®ƒæ¥å—ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨ç”¨æˆ·è¾“å…¥çš„æ ¼å¼åŒ–å®ƒï¼Œå¹¶ä»LLMè¿”å›å“åº”ã€‚

æˆ‘ä»¬é¦–å…ˆè¦åˆ›å»ºä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼š

from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)
ç„¶åï¼Œåˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„é“¾ï¼Œå®ƒå°†æ¥å—ç”¨æˆ·çš„è¾“å…¥ï¼Œç”¨å®ƒæ¥æ ¼å¼åŒ–æç¤ºï¼Œç„¶åå°†å…¶å‘é€åˆ°LLMã€‚

from langchain.chains import LLMChain
chain = LLMChain(llm=llm, prompt=prompt)

# Run the chain only specifying the input variable.
print(chain.run("colorful socks"))

    Colorful Toes Co.

'''
å¦‚æœæœ‰å¤šä¸ªå˜é‡ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªå­—å…¸ä¸€æ¬¡è¾“å…¥å®ƒä»¬ã€‚
'''
prompt = PromptTemplate(
    input_variables=["company", "product"],
    template="What is a good name for {company} that makes {product}?",
)
chain = LLMChain(llm=llm, prompt=prompt)
print(chain.run({
    'company': "ABC Startup",
    'product': "colorful socks"
    }))

    Socktopia Colourful Creations.
ä¹Ÿå¯ä»¥åœ¨LLMChainä¸­ä½¿ç”¨ä¸€ä¸ªèŠå¤©æ¨¡å‹ï¼š

from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
)
human_message_prompt = HumanMessagePromptTemplate(
        prompt=PromptTemplate(
            template="What is a good name for a company that makes {product}?",
            input_variables=["product"],
        )
    )
chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])
chat = ChatOpenAI(temperature=0.9)
chain = LLMChain(llm=chat, prompt=chat_prompt_template)
print(chain.run("colorful socks"))

    Rainbow Socks Co.
é“¾çš„åºåˆ—åŒ–ï¼Œä¿å­˜é“¾åˆ°ç£ç›˜ï¼Œä»ç£ç›˜åŠ è½½é“¾ï¼š
Serialization | ï¸ Langchain

æ€»ç»“
LangChain ä¸ºç‰¹å®šç”¨ä¾‹æä¾›äº†å¤šç§ç»„ä»¶ï¼Œä¾‹å¦‚ä¸ªäººåŠ©ç†ã€æ–‡æ¡£é—®ç­”ã€èŠå¤©æœºå™¨äººã€æŸ¥è¯¢è¡¨æ ¼æ•°æ®ã€ä¸ API äº¤äº’ã€æå–ã€è¯„ä¼°å’Œæ±‡æ€»ã€‚é€šè¿‡æä¾›æ¨¡å—åŒ–å’Œçµæ´»çš„æ–¹æ³•ç®€åŒ–äº†æ„å»ºé«˜çº§è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºçš„è¿‡ç¨‹ã€‚é€šè¿‡äº†è§£ç»„ä»¶ã€é“¾ã€æç¤ºæ¨¡æ¿ã€è¾“å‡ºè§£æå™¨ã€ç´¢å¼•ã€æ£€ç´¢å™¨ã€èŠå¤©æ¶ˆæ¯å†å²è®°å½•å’Œä»£ç†ç­‰æ ¸å¿ƒæ¦‚å¿µï¼Œå¯ä»¥åˆ›å»ºé€‚åˆç‰¹å®šéœ€æ±‚çš„è‡ªå®šä¹‰è§£å†³æ–¹æ¡ˆã€‚LangChain èƒ½å¤Ÿé‡Šæ”¾è¯­è¨€æ¨¡å‹çš„å…¨éƒ¨æ½œåŠ›ï¼Œå¹¶åœ¨å¹¿æ³›çš„ç”¨ä¾‹ä¸­åˆ›å»ºæ™ºèƒ½çš„ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åº”ç”¨ç¨‹åºã€‚

n




# RAG æŠ€æœ¯å®è·µæŒ‡å—

## æ ¸å¿ƒç†å¿µ

**RAG ä¸æ˜¯ ä¸æ˜¯æ›¿æ¢ï¼Œè€Œæ˜¯æ‰©å……**ï¼šRAGä¸æ˜¯ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯"ä»£æ›¿"åŸå§‹é—®é¢˜ï¼Œè€Œæ˜¯å°†å®ƒä½œä¸ºè¡¥å……ææ–™ï¼Œå’ŒåŸå§‹é—®é¢˜ä¸€åŒæä¾›ç»™æ¨¡å‹ã€‚

## æ–‡æ¡£åŠ è½½

### é¢„å¤„ç†å™¨é€‰æ‹©æŒ‡å—

| æ–‡ä»¶ç±»å‹ | æ¨è loader | å…ˆåˆ‡å…ˆåˆ‡æ ‡é¢˜ï¼Ÿ | å†åˆ‡é•¿åº¦ | Overlap | é¢å¤–é…ç½® |
|---------|-------------|-----------|----------|---------|----------|
| ä¸­æ–‡ PDF | PyPDFium2Loader | å¦ | 500 å­— | 100 | separators å¸¦å¥å· |
| Markdown åšå®¢ | MDHeaderSplitter | æ˜¯ | 1000 å­— | 200 | é¡ºåºä¸å¯é€† |
| Python æºç  | LanguageSplitter | å¦ | 600 token | 60 | language="python" |
| æ‰«æåˆåŒ | AmazonTextractPDFLoader | å¦ | 400 å­— | 80 | OCR ååŠ ç©ºæ ¼æ­£åˆ™ |
| Excel æŠ¥è¡¨ | pandas è‡ªå»º | å¦ | 300 å­— | 50 | metadata å¸¦ sheet å |

### å…³é”®è¦ç‚¹

> **âš ï¸ é‡è¦æé†’**
> 
> - **loader é€‰é”™ = åç»­å…¨ç™½æ­ç™½æ­**
> - **OCR é’±åˆ«çœï¼Œçœäº†å°±å¹»è§‰**
> - **é¢„å¤„ç†/æ¸…æ´—**ï¼šæ¸…ç†ä¸å¿…è¦çš„å­—ç¬¦ã€æ ¼å¼åŒ–ä»£ç ã€çº æ­£æ‹¼å†™é”™è¯¯ç­‰ï¼Œä»¥æé«˜æ–‡æœ¬è´¨é‡
> - splitter è°ƒå‚åˆ«å‡­æ„Ÿè§‰ï¼Œç”¨ tiktoken æ•° tokenï¼Œå†è·‘ä¸€éæ£€ç´¢è¯„æµ‹è„šæœ¬ï¼Œçœ‹å¬å›ç‡æ¶¨æ²¡æ¶¨
> - ä»»ä½•åˆ‡åˆ†æ”¹å®Œï¼Œé‡æ–°å»ºå‘é‡åº“ï¼Œæ—§åº“ä¸ä¼šè‡ªåŠ¨æ›´æ–°ï¼

## æ–‡æ¡£åˆ†å‰²

### Chunk Size é…ç½®è¡¨

| ä»»åŠ¡ç±»å‹ | æ¨è Size | æ¨è Overlap (Î·) | è®¾è®¡åŸç† |
|---------|-----------|-----------------|----------|
| å®¢æœ FAQ | 400-600 å­— | 20% | ç­”æ¡ˆé€šå¸¸ä¸€æ®µï¼Œè·¨å—å°‘ |
| æ³•å¾‹åˆåŒ | 800-1200 å­— | 15-20% | æ¡æ¬¾éœ€å®Œæ•´ï¼Œoverlap ä¿"ç¬¬ 3 æ¡"ä¸è¢«åˆ‡ |
| æŠ€æœ¯ API æ–‡æ¡£ | 300-500 å­— | 25% | å‡½æ•° å‡½æ•°å+ç¤ºä¾‹ä»£ç å¸¸è·¨ 2 æ®µ |
| è®ºæ–‡ | 600-800 å­— | 20% | å…¼é¡¾å›¾è¡¨æ ‡é¢˜ä¸æ­£æ–‡ |
| å¯¹è¯æ—¥å¿— | 150-250 å­— | 30% | æ¯å¥çŸ­ï¼Œé«˜ overlap é˜²"ä¸Šä¸‹æ–‡å¤±å¿†" |

**è®¡ç®—å…¬å¼**: `overlap = Î· Ã— chunk_size`

## å‘é‡åŒ–ï¼ˆåµŒå…¥ï¼‰

### åŸºæœ¬æ¦‚å¿µ

**Embedding** å°±æ˜¯æŠŠ"ä»»æ„ç¬¦å·åºåˆ—"â†’ é«˜ç»´æµ®ç‚¹å‘é‡ï¼Œä½¿å¾— **è¯­ä¹‰ç›¸ä¼¼ â‰ˆ æ¬§å¼è·ç¦»è¿‘**ï¼Œåé¢æ‰€æœ‰æ£€ç´¢ã€èšç±»ã€åˆ†ç±»ã€å¯è§†åŒ–éƒ½é è¿™ä¸€é”¤å­ã€‚

### æ¨¡å‹é€‰å‹å†³ç­–çŸ©é˜µ

| å†³ç­–å› ç´  | é€‰é¡¹ | å½±å“è¯´æ˜ |
|---------|------|----------|
| **â‘  è¯­ç§** | çº¯ä¸­æ–‡ / ä¸­è‹±æ··åˆ / å¤šè¯­è¨€ | å†³å®šæ˜¯å¦ç”¨åŒè¯­æˆ–å¤šè¯­æ¨¡å‹ |
| **â‘¡ é•¿åº¦** | å¹³å‡ 128 token vs 512 token | çŸ­æ–‡æœ¬é€‰ 128 ç»´åº¦ä½çœé’±ï¼›é•¿æ–‡æ¡£éœ€ 512 ä»¥ä¸Š |
| **â‘¢ ç»´åº¦** | 384 / 768 / 1024 / 1536 | ç»´åº¦â†‘ç²¾åº¦â†‘ä½†å‘é‡åº“å†…å­˜â†‘<br>1536 ç»´ 100 M æ¡ â‰ˆ 600 GB åŸå§‹ RAM |
| **â‘£ æ˜¯å¦å¾®è°ƒ** | é€šç”¨ vs é¢†åŸŸå¾®è°ƒ | åŒ»ç–—ã€æ³•å¾‹æœ¯è¯­å¿…é¡»å¾®è°ƒï¼Œå¦åˆ™æ£€ç´¢ TOP10 ä¸€åŠé£˜ |

### å¤„ç†æµç¨‹

1. **Embedding æ¨¡å‹** â†’ æŠŠæ–‡æœ¬/å›¾åƒå˜æˆå‘é‡
2. **å‘é‡åº“** â†’ æ¥æ”¶ (å‘é‡, åŸæ–‡,åŸæ–‡, å…ƒæ•°æ®) ä¸‰å…ƒç»„ï¼Œå»ºç´¢å¼•  
3. **æŸ¥è¯¢æ—¶** â†’ å‘é‡åº“æŠŠç”¨æˆ·é—®é¢˜çš„å‘é‡åšè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼Œè¿”å› Top-K åŸæ–‡

### "ä¸€" vs "å¤š"å…³ç³»

- **"ä¸€"ä¸ªç´¢å¼•**ï¼šæŒ‡çŸ¥è¯†åº“ä¸­çš„ä¸€ä¸ªæ–‡æ¡£ã€ä¸€ä¸ªç« èŠ‚æˆ–ä¸€ä¸ªå®Œæ•´çš„ç­”æ¡ˆï¼Œé€šå¸¸å¯¹åº”å”¯ä¸€IDï¼ˆå¦‚ `doc_id_123`ï¼‰
- **"å¤š"ä¸ªå‘é‡æ¡ç›®**ï¼šä¸ºè¡¨ç¤ºè¿™ä¸ª"ç´¢å¼•"è€Œç”Ÿæˆçš„å¤šä¸ªå‘é‡ï¼Œé€šè¿‡å¯¹é•¿æ–‡æœ¬åˆ‡åˆ†çš„æ¯ä¸ª"å—"è¿›è¡ŒåµŒå…¥å¾—åˆ°

## æ£€ç´¢ç­–ç•¥

### ä¸¤é˜¶æ®µæ£€ç´¢å¯¹æ¯”

| ç‰¹æ€§ | åˆæ­¥æ£€ç´¢ | é‡æ’ |
|------|----------|------|
| **ç›®æ ‡** | é«˜å¬å›ç‡ï¼šæ‰¾å‡ºæ‰€æœ‰å¯èƒ½ç›¸å…³çš„æ–‡æ¡£ | é«˜ç²¾åº¦ï¼šç¡®ä¿æœ€ç›¸å…³çš„æ–‡æ¡£æ’åœ¨æœ€å‰ |
| **èŒƒå›´** | æ•´ä¸ªæ–‡æ¡£åº“ï¼ˆç™¾ä¸‡/åƒä¸‡çº§ï¼‰ | åˆæ­¥æ£€ç´¢å‡ºçš„å€™é€‰é›†ï¼ˆç™¾/åƒçº§ï¼‰ |
| **æ¨¡å‹** | åŒç¼–ç å™¨ã€BM25ï¼ˆå¿«é€Ÿï¼‰ | äº¤å‰ç¼–ç å™¨ã€åˆ—è¡¨å¼æŸå¤±æ¨¡å‹ï¼ˆæ…¢é€Ÿä½†ç²¾å‡†ï¼‰ |
| **è§’è‰²** | æ’’ç½‘ | ç²¾é€‰ |







## å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

### å¦‚ä½•åœ¨ RAG ç³»ç»Ÿä¸­ç¼“è§£"å¤è¯»æœº"é—®é¢˜ï¼Ÿ

#### ğŸ¯ è°ƒæ•´ç”Ÿæˆå‚æ•°

- **é€‚å½“æé«˜æ¸©åº¦**  
  ä¾‹å¦‚ä» 0.1 æé«˜åˆ° 0.3 æˆ– 0.5ï¼Œå¼•å…¥ä¸€äº›åˆ›é€ æ€§ã€‚

- **å¯ç”¨å¹¶åŠ å¼ºé‡å¤æƒ©ç½š**  
  ç¡®ä¿ `repetition_penalty` æˆ–ç±»ä¼¼å‚æ•°è¢«å¼€å¯å¹¶è®¾ç½®ä¸ºä¸€ä¸ªæœ‰æ•ˆçš„å€¼ã€‚

- **è°ƒæ•´ Top-p**  
  å°è¯•ä½¿ç”¨æ›´å¤§çš„ `top_p` å€¼ä»¥æ‰©å¤§å€™é€‰è¯æ± ã€‚

#### ğŸ” ä¼˜åŒ–æ£€ç´¢è´¨é‡

- **ç¡®ä¿æ£€ç´¢è´¨é‡**  
  ä¿è¯æ£€ç´¢åˆ°çš„æ–‡æ¡£å—æ˜¯**ç›¸å…³ã€é«˜è´¨é‡ä¸”ä¿¡æ¯å……è¶³**çš„ã€‚

- **é‡‡ç”¨å…ˆè¿›æ£€ç´¢æŠ€æœ¯**  
  å¦‚æœä¸€ä¸ªé—®é¢˜éœ€è¦å¤šè§’åº¦ä¿¡æ¯ï¼Œå°è¯•ä½¿ç”¨ **Multi-Query** æˆ– **HyDE** æŠ€æœ¯æ¥è·å¾—æ›´å…¨é¢çš„ä¸Šä¸‹æ–‡ã€‚

#### ğŸ“ æ”¹è¿› Prompt å·¥ç¨‹

- **åŠ å…¥æ˜ç¡®æŒ‡ä»¤**  
  åœ¨ Prompt ä¸­åŠ å…¥æ˜ç¡®çš„æŒ‡ä»¤ï¼Œå¦‚ï¼š  
  > "è¯·ç”¨æµç•…ã€å¤šæ ·åŒ–çš„è¯­è¨€å›ç­”ï¼Œé¿å…é‡å¤ç›¸åŒçš„è¯æ±‡å’Œå¥å¼ã€‚"

- **è®¾å®šç”Ÿæˆé•¿åº¦é™åˆ¶**  
  åœ¨ä»£ç å±‚é¢å¼ºåˆ¶é™åˆ¶å•æ¬¡å›å¤çš„æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢å¾ªç¯æ— é™è¿›è¡Œä¸‹å»ã€‚

#### ğŸ’ æ€»ç»“

**"å¤è¯»æœº"ç°è±¡**æ˜¯ LLM åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­é™·å…¥çš„ä¸€ç§"å±€éƒ¨æœ€ä¼˜"é™·é˜±ï¼Œæ˜¯æ¨¡å‹ç®—æ³•ã€å‚æ•°è®¾ç½®å’Œè¾“å…¥ä¸Šä¸‹æ–‡å…±åŒä½œç”¨ä¸‹çš„å¤±è´¥è¡¨ç°ã€‚ç†è§£å’Œè§£å†³å®ƒéœ€è¦å¯¹ LLM çš„å·¥ä½œåŸç†æœ‰æ·±å…¥çš„äº†è§£ã€‚



### RAG ç´¢å¼•æ›´æ–°è§¦å‘æ¡ä»¶

#### ğŸš¨ ç¡¬æ€§è§¦å‘æ¡ä»¶

ä»¥ä¸‹æ˜¯å¿…é¡»ç«‹å³å¯åŠ¨ç´¢å¼•æ›´æ–°çš„æƒ…å†µï¼š

- **ğŸ“„ æ–‡æ¡£æ•°é‡é˜ˆå€¼**  
  æ–°å¢å®˜æ–¹æ–‡æ¡£è¶…è¿‡ **50é¡µ** æˆ–åˆ é™¤é‡è¦æ–‡æ¡£

- **ğŸ”„ ä¸šåŠ¡æµç¨‹å˜æ›´**  
  å…³é”®ä¸šåŠ¡æµç¨‹å‘ç”Ÿé‡å¤§å˜æ›´ï¼Œå½±å“ç°æœ‰æ–‡æ¡£çš„æœ‰æ•ˆæ€§

- **ğŸ‘¥ ç”¨æˆ·åé¦ˆæŒ‡å‘æ€§**  
  æ”¶åˆ°å¤šæ¬¡ç”¨æˆ·åé¦ˆå›ç­”ä¸å‡†ï¼Œä¸”æ˜ç¡®æ¶‰åŠç‰¹å®šæ–‡æ¡£å†…å®¹

- **âœï¸ æ–‡æ¡£ä¿®æ”¹è§„æ¨¡**  
  æ–‡æ¡£ä¿®æ”¹é‡è¶…è¿‡çŸ¥è¯†åº“æ€»é‡çš„ **10%**

- **ğŸ¯ é¢„è®¾ä¸šåŠ¡äº‹ä»¶**  
  é¢„å…ˆè®¡åˆ’çš„ä¸šåŠ¡æ´»åŠ¨ï¼Œå¦‚ï¼š
  - äº§å“å‘å¸ƒä¼š
  - æ³•è§„ç”Ÿæ•ˆæ—¥
  - ç³»ç»Ÿå‡çº§èŠ‚ç‚¹

#### âš ï¸ è½¯æ€§è§¦å‘æ¡ä»¶

ä»¥ä¸‹æƒ…å†µå»ºè®®å°½å¿«å®‰æ’ç´¢å¼•æ›´æ–°ï¼š

- **ğŸ“Š æ£€ç´¢æ•ˆæœä¸‹æ»‘**  
  æ£€ç´¢æ•ˆæœè¯„ä¼°åˆ†æ•°ä¸‹é™ **15%** ä»¥ä¸Š

- **ğŸ•³ï¸ çŸ¥è¯†ç¼ºå£æš´éœ²**  
  å‘ç°æ˜æ˜¾çš„çŸ¥è¯†ç¼ºå£æˆ–æ–‡æ¡£ä¸­å­˜åœ¨é”™è¯¯ä¿¡æ¯

#### ğŸ’° æˆæœ¬ä¸é£é™©è¯„ä¼°

| æ›´æ–°é¢‘ç‡ | ä¼˜åŠ¿ | é£é™© | é€‚ç”¨åœºæ™¯ |
|---------|------|------|----------|
| **å®æ—¶** | ä¿¡æ¯é›¶å»¶è¿Ÿ | â€¢ è®¡ç®—æˆæœ¬æé«˜<br>â€¢ ç³»ç»Ÿå¤æ‚åº¦é«˜ | é‡‘èäº¤æ˜“ã€ç´§æ€¥å‘Šè­¦ |
| **å°æ—¶çº§** | è¾ƒå¥½çš„æ—¶æ•ˆæ€§ | â€¢ ä¸­ç­‰èµ„æºæ¶ˆè€—<br>â€¢ éœ€è¦ç›‘æ§é˜Ÿåˆ— | æ–°é—»èšåˆã€å¸‚åœºåˆ†æ |
| **å¤©çº§** | å¹³è¡¡æˆæœ¬ä¸æ”¶ç›Š | â€¢ å¯èƒ½å­˜åœ¨ä¸€å¤©çš„æ•°æ®å»¶è¿Ÿ | å¤§å¤šæ•°ä¼ä¸šå†…éƒ¨çŸ¥è¯†åº“ |
| **å‘¨çº§** | æˆæœ¬æ•ˆç›Šæœ€ä½³ | â€¢ æœ€é•¿ä¸€å‘¨å»¶è¿Ÿ<br>â€¢ æ‰¹é‡å¤„ç†å‹åŠ›å¤§ | æ ‡å‡†ä¼ä¸šçŸ¥è¯†ç®¡ç† |
| **æœˆçº§** | ç»´æŠ¤æˆæœ¬æœ€ä½ | â€¢ ä¿¡æ¯ä¸¥é‡æ»å<br>â€¢ ç”¨æˆ·ä½“éªŒå·® | å½’æ¡£æ–‡æ¡£ã€å†å²èµ„æ–™ |

#### ğŸ”§ å®æ“ Checklist

- ** æ›´æ–°å‰çš„æ£€æŸ¥æ¸…å•

- [ ] **å¤‡ä»½ç°æœ‰ç´¢å¼•** - é˜²æ­¢æ›´æ–°å¤±è´¥æ— æ³•å›æ»š
- [ ] **éªŒè¯æ•°æ®è´¨é‡** - é¿å…åƒåœ¾æ•°æ®å…¥åº“
- [ ] **é¢„ä¼°èµ„æºéœ€æ±‚** - é˜²æ­¢æ›´æ–°è¿‡ç¨‹ä¸­èµ„æºè€—å°½
| [ ] **å®‰æ’ç»´æŠ¤çª—å£** - å‘ŠçŸ¥ç”¨æˆ·å¯èƒ½çš„æœåŠ¡å½±å“

- ** æ›´æ–°åçš„éªŒè¯æ¸…å•

- [ ] **æŠ½æ ·æµ‹è¯•æ£€ç´¢** - ç¡®è®¤æ–°æ—§æ–‡æ¡£éƒ½èƒ½è¢«æ­£ç¡®æŸ¥åˆ°
- [ ] **æ¯”å¯¹å›ç­”è´¨é‡** - ç¡®ä¿æ›´æ–°åç­”æ¡ˆæœªé€€åŒ–
- [ ] **æ›´æ–°ç‰ˆæœ¬æ ‡ç­¾** - è®°å½•æ­¤æ¬¡æ›´æ–°çš„å†…å®¹å’Œæ—¶é—´



### SelfQuery åœ¨ RAG ç³»ç»Ÿä¸­çš„å®šä½ä¸å®è·µ

#### â“ æ ¸å¿ƒé—®é¢˜ï¼šåªç”¨ SelfQuery å¤Ÿå—ï¼Ÿ

**ç®€çŸ­å›ç­”**ï¼šä¸å¤Ÿã€‚SelfQuery åªæ˜¯ä¸€ä¸ª**å¼ºæœ‰åŠ›çš„è¡¥å……å·¥å…·**ï¼Œè€Œéä¸‡èƒ½è§£å†³æ–¹æ¡ˆã€‚

---

#### ğŸ”„ SelfQuery çš„å·¥ä½œè¾¹ç•Œ

- SelfQuery æ“…é•¿å¤„ç†çš„æŸ¥è¯¢ç±»å‹
| æŸ¥è¯¢ç±»å‹ | ç¤ºä¾‹ | è½¬æ¢ç»“æœ |
|---------|------|----------|
| **æ˜ç¡®çš„æ—¶é—´èŒƒå›´** | â€œå»å¹´çš„é”€å”®æŠ¥å‘Šâ€ | `filter={"year": 2023}` |
| **ç‰¹å®šçš„å±æ€§æ¡ä»¶** | â€œæŠ€æœ¯éƒ¨çš„é¡¹ç›®æ–‡æ¡£â€ | `filter={"department": "æŠ€æœ¯éƒ¨"}` |
| **ç»„åˆè¿‡æ»¤æ¡ä»¶** | â€œ2023å¹´æŠ€æœ¯éƒ¨çš„é¡¹ç›®æ–‡æ¡£â€ | `filter={"year": 2023, "department": "æŠ€æœ¯éƒ¨"}` |

- SelfQuery æ— æ³•å¤„ç†çš„æŸ¥è¯¢ç±»å‹
| æŸ¥è¯¢ç±»å‹ | ç¤ºä¾‹ | åŸå› åˆ†æ |
|---------|------|----------|
| **çº¯è¯­ä¹‰æŸ¥è¯¢** | â€œä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µâ€ | æ— æ˜ç¡®å…ƒæ•°æ®æ¡ä»¶ |
| **å¤æ‚æ¨ç†éœ€æ±‚** | â€œæ¯”è¾ƒä¸€ä¸‹æˆ‘ä»¬å…¬å¸ä»Šå¹´å’Œå»å¹´çš„è¥æ”¶çŠ¶å†µâ€ | éœ€è¦æ•´åˆå¤šä¸ªæ–‡æ¡£ä¿¡æ¯å¹¶è¿›è¡Œæ¨ç† |
| **éšå«çŸ¥è¯†æŒ–æ˜** | â€œæˆ‘ä»¬çš„äº§å“åœ¨å“ªäº›æ–¹é¢æ¯”ç«äº‰å¯¹æ‰‹æœ‰ä¼˜åŠ¿ï¼Ÿâ€ | éœ€è¦ä»å¤šä¸ªæ–‡æ¡£ä¸­æç‚¼å’Œæ€»ç»“ |

---

## ğŸ¯ ç°å®ä¸–ç•Œçš„æŸ¥è¯¢åˆ†å¸ƒ

### å…¸å‹ä¼ä¸šåœºæ™¯æŸ¥è¯¢æ¯”ä¾‹ä¼°ç®—
```mermaid
pie title RAG æŸ¥è¯¢ç±»å‹åˆ†å¸ƒ
    "çº¯è¯­ä¹‰æŸ¥è¯¢" : 40
    "æ··åˆæŸ¥è¯¢" : 35
    "çº¯è¿‡æ»¤æŸ¥è¯¢" : 25