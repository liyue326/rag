# rag

# prompt
 - 指令在大量数据训练的预训练模型下作用不大
 - 让我们一步一步来思考 这个技巧是否普遍有效
 - 模型的能力取决于上下文  如果 GPT-3 在一个简单的逻辑问题上出错，那么它一定无法处理简单的逻辑。这是上下文问题
 - 如何提高复杂任务的可靠性
    本文的其余部分分享了提高大型语言模型在复杂任务上可靠性的技巧。虽然其中一些技巧特定于某些类型的问题，但许多技巧都是基于可以广泛应用于各种任务的通用原则，例如：

    给出更清晰的指令
    将复杂任务分解为更简单的子任务
    构建指令以保持模型在任务上
    提示模型在回答前进行解释
    要求对多种可能的答案进行论证，然后综合
    生成多个输出，然后使用模型选择最佳的一个
    微调定制模型以最大化性能